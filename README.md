# CS-311-Project
---

# üß© Project Plan: Smart Resume Analyzer + Company Fit Finder

## üéØ M·ª•c ti√™u ch√≠nh

1. **CV Analyzer**

   * Ph√¢n t√≠ch b·ªë c·ª•c CV (layout).
   * ƒê∆∞a feedback chi ti·∫øt (thi·∫øu skill, thi·∫øu section, keyword ch∆∞a match).

2. **Company Fit Finder**

   * So kh·ªõp CV v·ªõi Job Description (JD).
   * G·ª£i √Ω c√¥ng ty/position ph√π h·ª£p nh·∫•t.
   * ƒê∆∞a ra l√Ω do (match/thi·∫øu skill n√†o).

3. **App Desktop**

   * Giao di·ªán k√©o-th·∫£ CV PDF.
   * Hi·ªÉn th·ªã feedback + danh s√°ch c√¥ng ty g·ª£i √Ω.

---

## üóÇÔ∏è C√¥ng ngh·ªá & Toolchain

* **CV Layout & Text Extraction**:

  * `PyMuPDF` ho·∫∑c `pdfplumber` (tr√≠ch xu·∫•t text).
  * `LayoutLM` ho·∫∑c `DocFormer` (hi·ªÉu b·ªë c·ª•c CV).

* **NLP (Feedback + Skill Extraction)**:

  * `spaCy` (NER cho skill, experience).
  * `sentence-transformers` (SBERT) ho·∫∑c OpenAI embeddings.
  * Fine-tuned BERT/GPT cho **feedback t·ª± ƒë·ªông**.

* **Matching & Ranking**:

  * `FAISS` (similarity search).
  * Cosine similarity tr√™n embeddings.

* **App Desktop**:

  * **PyQt5/PySide6** (Python GUI).
  * Ho·∫∑c **Electron + FastAPI backend** (n·∫øu mu·ªën UI ƒë·∫πp ki·ªÉu web).

---

## üìÖ Roadmap chi ti·∫øt (6 tu·∫ßn)

### üîπ Tu·∫ßn 1: Foundation

* Thu th·∫≠p CV m·∫´u (PDF) v√† v√†i JD th·∫≠t t·ª´ LinkedIn/VietnamWorks.
* X√¢y pipeline ƒë·ªçc CV PDF ‚Üí tr√≠ch xu·∫•t text + layout c∆° b·∫£n.
* L√†m giao di·ªán desktop ƒë∆°n gi·∫£n (drag & drop CV).

**Deliverable**: App m·ªü ƒë∆∞·ª£c CV, hi·ªÉn th·ªã text.

---

### üîπ Tu·∫ßn 2: CV Analyzer MVP

* D√πng NLP (spaCy + keyword matching) ƒë·ªÉ ph√°t hi·ªán:

  * Skills, Education, Experience, Certificates.
* Sinh feedback c∆° b·∫£n: thi·∫øu skill, thi·∫øu section.
* Hi·ªÉn th·ªã feedback tr√™n GUI.

**Deliverable**: Ng∆∞·ªùi d√πng th·∫£ CV v√†o ‚Üí feedback text hi·ªÉn th·ªã.

---

### üîπ Tu·∫ßn 3: Job Description Parser

* X√¢y parser cho JD (text ho·∫∑c JSON m·∫´u).
* Tr√≠ch xu·∫•t skill, y√™u c·∫ßu t·ª´ JD.
* Chu·∫©n h√≥a skill th√†nh embedding (SBERT / OpenAI).

**Deliverable**: H·ªá th·ªëng ƒë·ªçc ƒë∆∞·ª£c JD, li·ªát k√™ skill y√™u c·∫ßu.

---

### üîπ Tu·∫ßn 4: Matching System

* Chuy·ªÉn CV + JD th√†nh embedding vector.
* T√≠nh cosine similarity ‚Üí match score.
* B·ªï sung ‚Äúgap analysis‚Äù (skill thi·∫øu, kinh nghi·ªám ch∆∞a ƒë·ªß).

**Deliverable**: Output d·∫°ng:

```
JD: AI Engineer @ FPT
Match: 82%
Missing: Docker, TensorFlow
Feedback: N√™n b·ªï sung d·ª± √°n ML c√≥ Docker.
```

---

### üîπ Tu·∫ßn 5: Company Fit Finder

* T·∫°o danh s√°ch JD (crawl ho·∫∑c nh·∫≠p tay 5‚Äì10 JD).
* So kh·ªõp CV ‚Üí g·ª£i √Ω top 3 c√¥ng ty ph√π h·ª£p.
* Hi·ªÉn th·ªã l√Ω do match/mismatch.

**Deliverable**:

```
Top companies for you:
1. FPT AI Lab ‚Äì match 85% (thi·∫øu Docker).
2. VNG ‚Äì match 78% (thi·∫øu GoLang).
3. LINE Vietnam ‚Äì match 70% (thi·∫øu NLP).
```

---

### üîπ Tu·∫ßn 6: UI/UX + Polish

* L√†m UI g·ªçn g√†ng (tab ‚ÄúCV Feedback‚Äù + tab ‚ÄúCompany Fit‚Äù).
* Cho ph√©p t·∫£i l·∫°i CV ƒë√£ ch·ªânh s·ª≠a ‚Üí h·ªá th·ªëng so s√°nh tr∆∞·ªõc/sau.
* (Optional) T√≠ch h·ª£p API LinkedIn ƒë·ªÉ l·∫•y JD t·ª± ƒë·ªông.
* ƒê√≥ng g√≥i app th√†nh `.exe` (PyInstaller) ho·∫∑c desktop app (Electron).

**Deliverable**: App desktop ho√†n ch·ªânh, ch·∫°y offline.

---

## üìä T·ªïng k·∫øt gi√° tr·ªã

* **Sinh vi√™n d√πng**: ch·ªânh CV, t√¨m JD ph√π h·ª£p ‚Üí tƒÉng c∆° h·ªôi xin vi·ªác.
* **Nh√† tuy·ªÉn d·ª•ng d√πng**: so kh·ªõp nhanh ·ª©ng vi√™n.
* **B·∫°n**: c√≥ m·ªôt project **NLP + CV real-world** ƒë·ªÉ showcase tr√™n GitHub + portfolio, c·ª±c k·ª≥ ·∫•n t∆∞·ª£ng khi apply vi·ªác.

---

Tuy·ªát ‚Äî d∆∞·ªõi ƒë√¢y l√† **l·ªô tr√¨nh c·ª±c k·ª≥ chi ti·∫øt** (MVP ‚Üí production-ready) ƒë·ªÉ b·∫°n ph√°t tri·ªÉn **Smart Resume Analyzer + Company Fit Finder + CV Booster**. M√¨nh chia nh·ªè th√†nh milestones, tasks t·ª´ng b∆∞·ªõc, n·ªôi dung k·ªπ thu·∫≠t r√µ r√†ng, file/schema m·∫´u, test plan, deployment v√† stretch-goals ‚Äî ƒë·ªÉ b·∫°n c√≥ th·ªÉ copy ‚Äî paste l√†m theo ngay.

# T·ªïng quan ng·∫Øn

M·ª•c ti√™u: t·ª´ **CV (PDF)** t·∫°o profile c·∫•u tr√∫c ‚Üí ph√¢n t√≠ch, g·ª£i √Ω ch·ªânh s·ª≠a (rewrite/ATS/keyword), sinh CV t√πy ch·ªânh cho t·ª´ng JD ‚Üí match v·ªõi JD t·ª´ ngu·ªìn (crawl/upload) ‚Üí g·ª£i √Ω c√¥ng ty ph√π h·ª£p + learning path.
MVP focus: ch√≠nh x√°c tr√≠ch xu·∫•t (skills/exp), feedback c·ª• th·ªÉ, company ranking.

---

# MVP (ph·∫£i c√≥)

1. Drag & drop PDF CV ‚Üí extract text + layout.
2. Tr√≠ch xu·∫•t structured profile (skills, experiences, education, projects, certs).
3. So kh·ªõp 1 JD ‚Üí skill gap + suggestions + AI rewrite cho v√†i bullet points.
4. Company Fit: so s√°nh CV v·ªõi 5‚Äì10 JD m·∫´u ‚Üí top-3 companies + l√Ω do.
5. Desktop GUI ƒë∆°n gi·∫£n (PyQt/Electron) v·ªõi export PDF/Word c·ªßa CV ƒë√£ rewrite.

---

# Ki·∫øn tr√∫c h·ªá th·ªëng (t√≥m t·∫Øt)

* Frontend: Electron (React) ho·∫∑c PyQt5 (Python).
* Backend: FastAPI (Python) local (ch·∫°y c√πng m√°y ng∆∞·ªùi d√πng).
* Components: PDF reader ‚Üí Layout parser ‚Üí NLP extractor ‚Üí Embedding store + FAISS ‚Üí LLM prompt module (rewrite/cover letter) ‚Üí UI.
* Storage: local JSON files per user; optional SQLite ƒë·ªÉ index JD/companies.
* Models/libs: PyMuPDF/pdfplumber, Tesseract/EasyOCR, LayoutLM/Donut/DocTR, spaCy, sentence-transformers, FAISS, HuggingFace transformers or OpenAI for LLM.

---

# Schema d·ªØ li·ªáu m·∫´u (parsed\_cv.json)

```json
{
  "meta": {"filename":"cv.pdf","parsed_at":"2025-09-14T12:00:00+07:00"},
  "personal": {"name":"Vo Phuoc Thinh","email":"thinh@example.com","phone":"+84...","location":"Ho Chi Minh"},
  "summary":"Short professional summary...",
  "skills":[{"name":"Python","level":"advanced"},{"name":"Computer Vision","level":"intermediate"}],
  "projects":[{"title":"Image Classifier","desc":"Used PyTorch...","github":"https://github.com/...","start":"2024-05","end":"2024-08"}],
  "experience":[{"role":"Intern","company":"ABC","start":"2023-06","end":"2023-09","desc":"..."}],
  "education":[{"degree":"BSc Computer Science","school":"UIT","year":"2024"}],
  "certificates":["AWS Certified Cloud Practitioner"],
  "embeddings":{"skills_vector":[0.00123, ...], "full_cv_vector":[...]}
}
```

---

# L·ªô tr√¨nh c·ª±c k·ª≥ chi ti·∫øt (6 giai ƒëo·∫°n, m·ªói giai ƒëo·∫°n chia tasks nh·ªè)

## Giai ƒëo·∫°n 0 ‚Äî Chu·∫©n b·ªã (1‚Äì2 ng√†y)

* M·ª•c ti√™u: chu·∫©n b·ªã dataset, m√¥i tr∆∞·ªùng dev.
* Tasks:

  * T·∫°o repo GitHub (branch: `main`, `dev`).
  * Chu·∫©n dev env: Python 3.10+, virtualenv, nodejs n·∫øu d√πng Electron.
  * C√†i libs c∆° b·∫£n: `pip install fastapi uvicorn sentence-transformers spaCy pymupdf pdfplumber faiss-cpu transformers torch`.
  * Thu th·∫≠p d·ªØ li·ªáu: √≠t nh·∫•t 50 CV PDF (·∫©n danh) + 50 JD (c√°c v·ªã tr√≠ m·ª•c ti√™u).
  * T·∫°o notebook `explore.ipynb` ƒë·ªÉ th·ª≠ extract text t·ª´ PDF.

## Giai ƒëo·∫°n 1 ‚Äî PDF extraction + layout (MVP core)

* M·ª•c ti√™u: ƒë·ªçc PDF, t√°ch block (header, skill, exp).
* Tasks chi ti·∫øt:

  1. D√πng PyMuPDF/pdfplumber ƒë·ªÉ l·∫•y text + v·ªã tr√≠ bounding boxes. L∆∞u raw text + bbox.

     * Code g·ª£i √Ω: ƒë·ªçc page ‚Üí `page.get_text("dict")` ƒë·ªÉ l·∫•y blocks.
  2. (Optional) OCR cho ·∫£nh trong PDF: Tesseract/EasyOCR. Ch·ªâ b·∫≠t khi text missing.
  3. Heuristic rule-based layout parser: rules for headings (all caps, bold, keywords: "Experience", "Education", "Skills").

     * Vi·∫øt rules sequence: detect headings ‚Üí assign blocks to sections by proximity.
  4. (Advanced) Th·ª≠ LayoutLM/DocTR cho ch√≠nh x√°c h∆°n: fine-tune nh·ªè n·∫øu c·∫ßn.
* Deliverable: `parsed_cv.json` generation function.

## Giai ƒëo·∫°n 2 ‚Äî Skill & entity extraction (NLP)

* M·ª•c ti√™u: t·ª± ƒë·ªông nh·∫≠n di·ªán skills, role, dates, company, project.
* Tasks:

  1. Install spaCy + custom NER model or use rule-based + keyword list (fast).

     * Build canonical skill dictionary (normalize synonyms: "CV" ‚Üí "Computer Vision").
  2. Extract experiences: parse date ranges (regex), company names (heuristic + NER).
  3. Normalize skills: map raw tokens to canonical names using fuzzy matching (fuzzywuzzy/rapidfuzz).
  4. Test on sample set; compute extraction accuracy (precision/recall).
* Deliverable: structured profile with canonicalized skills.

## Giai ƒëo·∫°n 3 ‚Äî Embeddings & Matching core

* M·ª•c ti√™u: chuy·ªÉn CV + JD ‚Üí vectors; x√¢y similarity pipeline.
* Tasks:

  1. Choose embedding model: `sentence-transformers/all-mpnet-base-v2` (good default offline) OR OpenAI embeddings (if cloud).
  2. Compute embeddings:

     * `full_cv_vector` = embed(concat(summary + top N bullet points))
     * `skills_vector` = embed("Python, Docker, TensorFlow")
     * For each JD: compute `jd_vector` and `jd_skill_vector`.
  3. Index JD vectors in FAISS (flat index for MVP).
  4. Implement similarity scoring:

     * score\_full = cosine(full\_cv\_vector, jd\_vector)
     * skill\_overlap = jaccard(skills\_cv, skills\_jd) normalized
     * final\_score = weighted(sum)
     * Expose factors for explainability (show breakdown).
* Deliverable: ranking API `POST /match` returning top-K JD with breakdown.

## Giai ƒëo·∫°n 4 ‚Äî Feedback generator & AI rewrite

* M·ª•c ti√™u: feedback chi ti·∫øt + rewrite bullets, cover letter.
* Tasks:

  1. Build rule-based suggestions (ATS warnings, missing sections).
  2. Integrate LLM for high-quality rewrite:

     * If offline: use local LLM (Llama-like) or HF `gpt-neo` small; for quality, use OpenAI API (GPT-4/4o) if permitted.
     * Prompt templates:

       * Input: original bullet, role, skills. Output: rewritten bullet (concise, action/result).
  3. Create `rewrite_batch` endpoint: take top 5 bullets ‚Üí return rewrites with variations.
  4. Add cover letter generator (prompted with company JD + CV summary).
* Deliverable: `rewrite_preview` modal in UI; download rewritten CV.

## Giai ƒëo·∫°n 5 ‚Äî Company Fit Finder + UI polish

* M·ª•c ti√™u: crawl/import JD pool, rank companies, improve UI/UX.
* Tasks:

  1. Data source: manual JD upload / scrape LinkedIn/VietnamWorks (scraper optional).

     * Note: scraping LinkedIn may violate TOS; prefer manual upload or public job boards with API.
  2. Implement company profile metadata: `industry, size, remote, required_skills`.
  3. Ranking view: top 10 companies with reasons and action items (what to add to CV to bump score).
  4. UI polish: tabs ‚Äî CV Feedback / Rewrites / Company Fit / Apply Actions.
  5. Export: allow user to save new CV as PDF or DOCX (python-docx / reportlab).
* Deliverable: finished desktop app with full workflow.

## Giai ƒëo·∫°n 6 ‚Äî Testing, evaluation, deploy & optional extras

* M·ª•c ti√™u: harden, test, package.
* Tasks:

  1. Unit tests for parser, NER, embeddings, matching logic.
  2. Create evaluation dataset (label skills in 100 CVs) ‚Üí measure extraction metrics.
  3. UX testing: 5 users run their CVs ‚Üí collect qualitative feedback.
  4. Packaging:

     * If Python GUI: `pyinstaller --onefile main.py` and bundle.
     * If Electron + backend: build Electron app and include Python backend in installer (or deliver as separate binary).
  5. Optional: small backend cloud for heavy LLM calls (if using OpenAI).
* Deliverable: distributable `.exe` or `.dmg` and README install guide.

---

# Chi ti·∫øt k·ªπ thu·∫≠t / m·∫´u code & prompts (ƒë·ªÉ b·∫°n copy lu√¥n)

## 1) T√°ch text t·ª´ PDF (snippet)

```python
import fitz  # PyMuPDF
doc = fitz.open("cv.pdf")
pages = []
for page in doc:
    blocks = page.get_text("dict")["blocks"]
    pages.append(blocks)
# Save pages -> use bbox info for layout
```

## 2) Embedding v·ªõi sentence-transformers

```python
from sentence_transformers import SentenceTransformer, util
model = SentenceTransformer("all-mpnet-base-v2")
vec = model.encode("Python, Computer Vision", convert_to_tensor=True)
# cosine:
sim = util.cos_sim(vec1, vec2)
```

## 3) Prompt m·∫´u cho rewrite (OpenAI/GPT)

```
PROMPT:
You are an expert resume writer. Rewrite the following resume bullet to be professional, result-oriented, and concise. Keep it to one sentence. Include metric or impact if possible.

Original bullet: "built small tool to process images"
Role: "Computer Vision Intern"
Skills: "Python, OpenCV, PyTorch"

OUTPUT: <rewritten bullet>
```

---

# UI / UX Mockup (m√¥ t·∫£ nhanh)

1. Left panel: File upload + parsed sections (editable inline).
2. Middle panel: CV preview with highlights (yellow = missing keywords, red = ATS fail).
3. Right panel: Suggestions:

   * Skill Gap (list + priority)
   * Rewrite suggestions (Accept / Reject / Edit)
   * Top Companies (score + why)
4. Top bar: Export (PDF/DOCX), Generate Cover Letter, Customize for Job.

---

# KPI, ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng & test plan

* **Extraction accuracy**: target precision ‚â• 0.85 for skills (on test set).
* **Matching alignment**: A/B test final\_score ranking: recruiter blind test (n=20) ‚Üí % agreement with human ranking ‚â• 0.7.
* **User success metric**: % users who submit revised CV to apply within 2 weeks (collect via optional opt-in).
* **Unit tests**: parser edge cases, dates parsing, normalization.

# Risks & mitigation

* **Poor OCR on images** ‚Üí mitigation: prompt user to upload original PDF or request clearer scan; fallback OCR.
* **Ambiguous skill names** ‚Üí use canonical dictionary + fuzzy matching + manual mapping UI.
* **Legal/TOS scraping JD** ‚Üí avoid scraping LinkedIn; use official APIs or manual uploading.
* **Data privacy** ‚Üí all processing local by default; if using cloud LLMs, prompt consent and mask PII.

---

# Stretch goals (s·∫Ω khi·∫øn app ‚Äúr·∫•t n·ªïi b·∫≠t‚Äù)

* CV A/B testing: track which version got replies (user reports).
* Auto GitHub project summarizer (scan repo, auto-generate project blurb).
* Recruiter simulation: 10-sec scan score + ‚ÄúWhy rejected in 10s‚Äù heatmap.
* Marketplace: connect to local recruiters / internships.
* SaaS mode: multi-user, analytics dashboard, employer API.

---

# Tri·ªÉn khai & v·∫≠n h√†nh (ng·∫Øn g·ªçn)

* Local-first: t·∫•t c·∫£ x·ª≠ l√Ω offline (privacy). D√πng OpenAI/Cloud LLM ch·ªâ khi user b·∫≠t.
* Packaging: t·∫°o installer cho Windows/macOS + README.
* Release: GitHub repo + demo video (2‚Äì3 ph√∫t) + sample dataset (anonymized) ‚Üí gi√∫p tuy·ªÉn d·ª•ng tin t∆∞·ªüng.

---

# Checklist tri·ªÉn khai (t·ª´ng b∆∞·ªõc, tick-off)

1. [ ] Repo + env setup.
2. [ ] PDF ‚Üí parsed\_cv.json pipeline.
3. [ ] Skill extraction + canonicalization.
4. [ ] Embedding & FAISS index.
5. [ ] Single JD match API + explainability.
6. [ ] Rewrite API (LLM prompts).
7. [ ] Company ranking + UI.
8. [ ] Export rewritten CV & cover letter.
9. [ ] Unit tests + evaluation.
10. [ ] Packaging + release.

---

# Ba h√†nh ƒë·ªông b·∫°n c√≥ th·ªÉ l√†m ngay (c·ª±c th·ª±c t·∫ø)

1. T·∫°o repo GitHub v√† commit `README` + `requirements.txt`.
2. L·∫•y 10 CV PDF (·∫©n danh) + 10 JD, ch·∫°y th·ª≠ snippet PyMuPDF ƒë·ªÉ xem c·∫•u tr√∫c.
3. C√†i `sentence-transformers` v√† encode m·ªôt CV sample + m·ªôt JD sample, t√≠nh cosine similarity ‚Äî b·∫°n s·∫Ω th·∫•y pipeline c∆° b·∫£n ch·∫°y ƒë∆∞·ª£c.

---
Tuy·ªát ‚Äî d∆∞·ªõi ƒë√¢y l√† **l·ªô tr√¨nh c·ª±c k·ª≥ chi ti·∫øt** (MVP ‚Üí production-ready) ƒë·ªÉ b·∫°n ph√°t tri·ªÉn **Smart Resume Analyzer + Company Fit Finder + CV Booster**. M√¨nh chia nh·ªè th√†nh milestones, tasks t·ª´ng b∆∞·ªõc, n·ªôi dung k·ªπ thu·∫≠t r√µ r√†ng, file/schema m·∫´u, test plan, deployment v√† stretch-goals ‚Äî ƒë·ªÉ b·∫°n c√≥ th·ªÉ copy ‚Äî paste l√†m theo ngay.

# T·ªïng quan ng·∫Øn

M·ª•c ti√™u: t·ª´ **CV (PDF)** t·∫°o profile c·∫•u tr√∫c ‚Üí ph√¢n t√≠ch, g·ª£i √Ω ch·ªânh s·ª≠a (rewrite/ATS/keyword), sinh CV t√πy ch·ªânh cho t·ª´ng JD ‚Üí match v·ªõi JD t·ª´ ngu·ªìn (crawl/upload) ‚Üí g·ª£i √Ω c√¥ng ty ph√π h·ª£p + learning path.
MVP focus: ch√≠nh x√°c tr√≠ch xu·∫•t (skills/exp), feedback c·ª• th·ªÉ, company ranking.

---

# MVP (ph·∫£i c√≥)

1. Drag & drop PDF CV ‚Üí extract text + layout.
2. Tr√≠ch xu·∫•t structured profile (skills, experiences, education, projects, certs).
3. So kh·ªõp 1 JD ‚Üí skill gap + suggestions + AI rewrite cho v√†i bullet points.
4. Company Fit: so s√°nh CV v·ªõi 5‚Äì10 JD m·∫´u ‚Üí top-3 companies + l√Ω do.
5. Desktop GUI ƒë∆°n gi·∫£n (PyQt/Electron) v·ªõi export PDF/Word c·ªßa CV ƒë√£ rewrite.

---

# Ki·∫øn tr√∫c h·ªá th·ªëng (t√≥m t·∫Øt)

* Frontend: Electron (React) ho·∫∑c PyQt5 (Python).
* Backend: FastAPI (Python) local (ch·∫°y c√πng m√°y ng∆∞·ªùi d√πng).
* Components: PDF reader ‚Üí Layout parser ‚Üí NLP extractor ‚Üí Embedding store + FAISS ‚Üí LLM prompt module (rewrite/cover letter) ‚Üí UI.
* Storage: local JSON files per user; optional SQLite ƒë·ªÉ index JD/companies.
* Models/libs: PyMuPDF/pdfplumber, Tesseract/EasyOCR, LayoutLM/Donut/DocTR, spaCy, sentence-transformers, FAISS, HuggingFace transformers or OpenAI for LLM.

---

# Schema d·ªØ li·ªáu m·∫´u (parsed\_cv.json)

```json
{
  "meta": {"filename":"cv.pdf","parsed_at":"2025-09-14T12:00:00+07:00"},
  "personal": {"name":"Vo Phuoc Thinh","email":"thinh@example.com","phone":"+84...","location":"Ho Chi Minh"},
  "summary":"Short professional summary...",
  "skills":[{"name":"Python","level":"advanced"},{"name":"Computer Vision","level":"intermediate"}],
  "projects":[{"title":"Image Classifier","desc":"Used PyTorch...","github":"https://github.com/...","start":"2024-05","end":"2024-08"}],
  "experience":[{"role":"Intern","company":"ABC","start":"2023-06","end":"2023-09","desc":"..."}],
  "education":[{"degree":"BSc Computer Science","school":"UIT","year":"2024"}],
  "certificates":["AWS Certified Cloud Practitioner"],
  "embeddings":{"skills_vector":[0.00123, ...], "full_cv_vector":[...]}
}
```

---

# L·ªô tr√¨nh c·ª±c k·ª≥ chi ti·∫øt (6 giai ƒëo·∫°n, m·ªói giai ƒëo·∫°n chia tasks nh·ªè)

## Giai ƒëo·∫°n 0 ‚Äî Chu·∫©n b·ªã (1‚Äì2 ng√†y)

* M·ª•c ti√™u: chu·∫©n b·ªã dataset, m√¥i tr∆∞·ªùng dev.
* Tasks:

  * T·∫°o repo GitHub (branch: `main`, `dev`).
  * Chu·∫©n dev env: Python 3.10+, virtualenv, nodejs n·∫øu d√πng Electron.
  * C√†i libs c∆° b·∫£n: `pip install fastapi uvicorn sentence-transformers spaCy pymupdf pdfplumber faiss-cpu transformers torch`.
  * Thu th·∫≠p d·ªØ li·ªáu: √≠t nh·∫•t 50 CV PDF (·∫©n danh) + 50 JD (c√°c v·ªã tr√≠ m·ª•c ti√™u).
  * T·∫°o notebook `explore.ipynb` ƒë·ªÉ th·ª≠ extract text t·ª´ PDF.

## Giai ƒëo·∫°n 1 ‚Äî PDF extraction + layout (MVP core)

* M·ª•c ti√™u: ƒë·ªçc PDF, t√°ch block (header, skill, exp).
* Tasks chi ti·∫øt:

  1. D√πng PyMuPDF/pdfplumber ƒë·ªÉ l·∫•y text + v·ªã tr√≠ bounding boxes. L∆∞u raw text + bbox.

     * Code g·ª£i √Ω: ƒë·ªçc page ‚Üí `page.get_text("dict")` ƒë·ªÉ l·∫•y blocks.
  2. (Optional) OCR cho ·∫£nh trong PDF: Tesseract/EasyOCR. Ch·ªâ b·∫≠t khi text missing.
  3. Heuristic rule-based layout parser: rules for headings (all caps, bold, keywords: "Experience", "Education", "Skills").

     * Vi·∫øt rules sequence: detect headings ‚Üí assign blocks to sections by proximity.
  4. (Advanced) Th·ª≠ LayoutLM/DocTR cho ch√≠nh x√°c h∆°n: fine-tune nh·ªè n·∫øu c·∫ßn.
* Deliverable: `parsed_cv.json` generation function.

## Giai ƒëo·∫°n 2 ‚Äî Skill & entity extraction (NLP)

* M·ª•c ti√™u: t·ª± ƒë·ªông nh·∫≠n di·ªán skills, role, dates, company, project.
* Tasks:

  1. Install spaCy + custom NER model or use rule-based + keyword list (fast).

     * Build canonical skill dictionary (normalize synonyms: "CV" ‚Üí "Computer Vision").
  2. Extract experiences: parse date ranges (regex), company names (heuristic + NER).
  3. Normalize skills: map raw tokens to canonical names using fuzzy matching (fuzzywuzzy/rapidfuzz).
  4. Test on sample set; compute extraction accuracy (precision/recall).
* Deliverable: structured profile with canonicalized skills.

## Giai ƒëo·∫°n 3 ‚Äî Embeddings & Matching core

* M·ª•c ti√™u: chuy·ªÉn CV + JD ‚Üí vectors; x√¢y similarity pipeline.
* Tasks:

  1. Choose embedding model: `sentence-transformers/all-mpnet-base-v2` (good default offline) OR OpenAI embeddings (if cloud).
  2. Compute embeddings:

     * `full_cv_vector` = embed(concat(summary + top N bullet points))
     * `skills_vector` = embed("Python, Docker, TensorFlow")
     * For each JD: compute `jd_vector` and `jd_skill_vector`.
  3. Index JD vectors in FAISS (flat index for MVP).
  4. Implement similarity scoring:

     * score\_full = cosine(full\_cv\_vector, jd\_vector)
     * skill\_overlap = jaccard(skills\_cv, skills\_jd) normalized
     * final\_score = weighted(sum)
     * Expose factors for explainability (show breakdown).
* Deliverable: ranking API `POST /match` returning top-K JD with breakdown.

## Giai ƒëo·∫°n 4 ‚Äî Feedback generator & AI rewrite

* M·ª•c ti√™u: feedback chi ti·∫øt + rewrite bullets, cover letter.
* Tasks:

  1. Build rule-based suggestions (ATS warnings, missing sections).
  2. Integrate LLM for high-quality rewrite:

     * If offline: use local LLM (Llama-like) or HF `gpt-neo` small; for quality, use OpenAI API (GPT-4/4o) if permitted.
     * Prompt templates:

       * Input: original bullet, role, skills. Output: rewritten bullet (concise, action/result).
  3. Create `rewrite_batch` endpoint: take top 5 bullets ‚Üí return rewrites with variations.
  4. Add cover letter generator (prompted with company JD + CV summary).
* Deliverable: `rewrite_preview` modal in UI; download rewritten CV.

## Giai ƒëo·∫°n 5 ‚Äî Company Fit Finder + UI polish

* M·ª•c ti√™u: crawl/import JD pool, rank companies, improve UI/UX.
* Tasks:

  1. Data source: manual JD upload / scrape LinkedIn/VietnamWorks (scraper optional).

     * Note: scraping LinkedIn may violate TOS; prefer manual upload or public job boards with API.
  2. Implement company profile metadata: `industry, size, remote, required_skills`.
  3. Ranking view: top 10 companies with reasons and action items (what to add to CV to bump score).
  4. UI polish: tabs ‚Äî CV Feedback / Rewrites / Company Fit / Apply Actions.
  5. Export: allow user to save new CV as PDF or DOCX (python-docx / reportlab).
* Deliverable: finished desktop app with full workflow.

## Giai ƒëo·∫°n 6 ‚Äî Testing, evaluation, deploy & optional extras

* M·ª•c ti√™u: harden, test, package.
* Tasks:

  1. Unit tests for parser, NER, embeddings, matching logic.
  2. Create evaluation dataset (label skills in 100 CVs) ‚Üí measure extraction metrics.
  3. UX testing: 5 users run their CVs ‚Üí collect qualitative feedback.
  4. Packaging:

     * If Python GUI: `pyinstaller --onefile main.py` and bundle.
     * If Electron + backend: build Electron app and include Python backend in installer (or deliver as separate binary).
  5. Optional: small backend cloud for heavy LLM calls (if using OpenAI).
* Deliverable: distributable `.exe` or `.dmg` and README install guide.

---

# Chi ti·∫øt k·ªπ thu·∫≠t / m·∫´u code & prompts (ƒë·ªÉ b·∫°n copy lu√¥n)

## 1) T√°ch text t·ª´ PDF (snippet)

```python
import fitz  # PyMuPDF
doc = fitz.open("cv.pdf")
pages = []
for page in doc:
    blocks = page.get_text("dict")["blocks"]
    pages.append(blocks)
# Save pages -> use bbox info for layout
```

## 2) Embedding v·ªõi sentence-transformers

```python
from sentence_transformers import SentenceTransformer, util
model = SentenceTransformer("all-mpnet-base-v2")
vec = model.encode("Python, Computer Vision", convert_to_tensor=True)
# cosine:
sim = util.cos_sim(vec1, vec2)
```

## 3) Prompt m·∫´u cho rewrite (OpenAI/GPT)

```
PROMPT:
You are an expert resume writer. Rewrite the following resume bullet to be professional, result-oriented, and concise. Keep it to one sentence. Include metric or impact if possible.

Original bullet: "built small tool to process images"
Role: "Computer Vision Intern"
Skills: "Python, OpenCV, PyTorch"

OUTPUT: <rewritten bullet>
```

---

# UI / UX Mockup (m√¥ t·∫£ nhanh)

1. Left panel: File upload + parsed sections (editable inline).
2. Middle panel: CV preview with highlights (yellow = missing keywords, red = ATS fail).
3. Right panel: Suggestions:

   * Skill Gap (list + priority)
   * Rewrite suggestions (Accept / Reject / Edit)
   * Top Companies (score + why)
4. Top bar: Export (PDF/DOCX), Generate Cover Letter, Customize for Job.

---

# KPI, ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng & test plan

* **Extraction accuracy**: target precision ‚â• 0.85 for skills (on test set).
* **Matching alignment**: A/B test final\_score ranking: recruiter blind test (n=20) ‚Üí % agreement with human ranking ‚â• 0.7.
* **User success metric**: % users who submit revised CV to apply within 2 weeks (collect via optional opt-in).
* **Unit tests**: parser edge cases, dates parsing, normalization.

# Risks & mitigation

* **Poor OCR on images** ‚Üí mitigation: prompt user to upload original PDF or request clearer scan; fallback OCR.
* **Ambiguous skill names** ‚Üí use canonical dictionary + fuzzy matching + manual mapping UI.
* **Legal/TOS scraping JD** ‚Üí avoid scraping LinkedIn; use official APIs or manual uploading.
* **Data privacy** ‚Üí all processing local by default; if using cloud LLMs, prompt consent and mask PII.

---

# Stretch goals (s·∫Ω khi·∫øn app ‚Äúr·∫•t n·ªïi b·∫≠t‚Äù)

* CV A/B testing: track which version got replies (user reports).
* Auto GitHub project summarizer (scan repo, auto-generate project blurb).
* Recruiter simulation: 10-sec scan score + ‚ÄúWhy rejected in 10s‚Äù heatmap.
* Marketplace: connect to local recruiters / internships.
* SaaS mode: multi-user, analytics dashboard, employer API.

---

# Tri·ªÉn khai & v·∫≠n h√†nh (ng·∫Øn g·ªçn)

* Local-first: t·∫•t c·∫£ x·ª≠ l√Ω offline (privacy). D√πng OpenAI/Cloud LLM ch·ªâ khi user b·∫≠t.
* Packaging: t·∫°o installer cho Windows/macOS + README.
* Release: GitHub repo + demo video (2‚Äì3 ph√∫t) + sample dataset (anonymized) ‚Üí gi√∫p tuy·ªÉn d·ª•ng tin t∆∞·ªüng.

---

# Checklist tri·ªÉn khai (t·ª´ng b∆∞·ªõc, tick-off)

1. [ ] Repo + env setup.
2. [ ] PDF ‚Üí parsed\_cv.json pipeline.
3. [ ] Skill extraction + canonicalization.
4. [ ] Embedding & FAISS index.
5. [ ] Single JD match API + explainability.
6. [ ] Rewrite API (LLM prompts).
7. [ ] Company ranking + UI.
8. [ ] Export rewritten CV & cover letter.
9. [ ] Unit tests + evaluation.
10. [ ] Packaging + release.

---
